<!DOCTYPE HTML>
<!--
	Landed by HTML5 UP
	html5up.net | @n33co
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
 -->
<html>
	<head>
		<title>Reinforcement learning lab</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!-- [if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif] -->
		<link rel="stylesheet" href="../assets/css/main.css" />
		<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
		
		<!-- Generics -->
			<script src="../assets/js/jquery.min.js"></script>
			<script src="../assets/js/math.min.js"></script>
			<script src="../assets/js/jquery.csv.min.js"></script>
			<script src="../assets/js/jquery.scrolly.min.js"></script>
			<script src="../assets/js/jquery.dropotron.min.js"></script>
			<script src="../assets/js/jquery.scrollex.min.js"></script>
			<script src="../assets/js/skel.min.js"></script>
			<script src="../assets/js/util.js"></script>			

			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="../assets/js/main.js"></script>
		<!-- Math KaTeX -->
			<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.css">
			<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.js"></script>
		<!-- Plotting: Plot.ly JS -->
			<script type="text/javascript" src="../assets/js/mathjax/MathJax.js?config=TeX-AMS-MML_SVG"></script>
      <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
	</head>
	<body>

		<div id="page-wrapper">

			<!-- Header -->
				<header id="header">

					<h1 id="logo"><a href="../index.html">Receptive field tutorial</a></h1>
					<nav id="nav">
						<ul>
							<li><a href="../index.html">Learn</a></li>
						</ul>
					</nav>
				</header>

			<!-- Main -->
				<div id="main" class="wrapper style1">
					<div class="container">
						<header class="major">
							<h2>Receptive field tutorial</h2>
							<p>Gardner Lab</p>
						</header>

						<!-- Content -->
							<section id="content">
	<canvas style="display:none;" id="backcanvas" width=50 height=50></canvas> 
<!--   -->
<div id="block1">
	<h2>Receptive field tutorial</h2>
	<p>This tutorial is focused on helping you understand how receptive field mapping is performed today in fMRI experiments. Receptive field mapping is used to identify what part of the visual field a voxel is responsive to. You'll be coding the models introduced in this tutorial as you go along--the tutorial is focused on helping you build an intuition about what kind of data you should expect to see.</p>
	<h1>Learning goals</h1>
	After this tutorial you should have a better understanding of the following:
	<ul>
		<li>How the receptive field of neurons in visual cortex is identified using high contrast visual stimuli.</li>
		<li>How visual cortex shows a topography of receptive fields and how we can use that to identify cortical regions.</li>
		<li>How we can use the population receptive field encoding model to study the spatial distribution of information in cortex.</li>
	</ul>
</div>

<div id="block2">
	<h2>Part 1: Voxel responses to visual stimuli</h2>
	<p>In visual cortex individual neurons show feature selecitivity, preferring some input types over others. One peculiarity of visual cortex is that neurons are not only feature selective but spatially selective: they have a <b>receptive field</b>, a region of the visual field that they respond to. This selectivity is inherited from the retina where small groups of closely spaced retinal ganglion cells are pooled together as they send signals to the lateral geniculate nucleus and then to early visual cortex.</p>
	<img src="images/rgc_v1.png" width=700px/><br>
	<p>This spatial organization is extremely compelling. Neurons in visual cortex turn out to be topographically laid out into maps, where each map covers a hemifield or half-hemifield. These maps have been named V1, V2, V3, and so on. It goes farther as well, as it turns out that there is some  consistency in feature sensitivity across each map, so for example area MT covers a complete hemifield and is largely selective to motion direction, speed, and coherence. In contrast, area V4 shows sensitivity to color. Topographic organization and feature selectivity make visual cortex a great place to study sensory perception and cognitive functions.</p>
	<img src="images/mt_v4.png" width=500px/><br>
	<p>In this first section we're going to zoom down to the individual <b>voxel</b> level and look at how a voxel's receptive field changes can be used to predict how it will respond to a stimulus. We've created a demonstration to help you gain an intuition for how this works. You'll use the three classic stimuli used during <b>retinotopic mapping</b>, the fMRI procedure of showing high contrast stimuli crossing the visual field to collect data usable to find receptive fields. You'll see a display like the one below and your goal will be to answer the questions on the next page. You'll be able to choose among the stimulus options and control them by moving your cursor around the visual field. Once you've created a receptive field (click and drag), you'll see that the encoding model will predict a certain amount of neural activity and BOLD response based on the overlap between the stimulus and the current receptive field.</p>
	<img src="images/example1.png"/><br>
</div>

<div id="block3">
	<h2>Part 1: Voxel responses to visual stimuli</h2>
	<p>Use these questions to guide your exploration of the stimulus. You can click to select a different stimulus and you can click and drag in the visual field to create a receptive field.</p>
	<ul>
	<li>First simply explore the space a bit. Try creating different receptive fields and then testing how they respond to different overlaps of the stimuli. Can you predict the shape of the response based on your knowledge of neural activity and the related BOLD response?</li>
	<li>In classic retinotopy Wandell and colleagues used 12-second (?) periodic <b>wedges</b> and <b>rings</b> for mapping. They then used the phase to identify the angle and eccentricity that a given voxel preferred. They fit their data using sinusoids--try recreating this stimulus by hand, what positives and what negatives do you see to this approach?</li>
	<li>In more modern retinotopy researchers now fit the population receptive field model using <b>bars</b>. Try the bars out and then try to come up with a few reasons why bars a good stimulus to use, share these with your neighbor or the instructors.</li>
	<li>A common intuition among first-time retinotopy users is that it would be more efficient to show more bars at once, or display more things on the screen more quickly (note that usually the bars take 24 seconds to cross the screen, because we've accelerated the HRF here by about 3x you can mimic this by taking about 8 seconds to cross the field). Try showing faster moving bars to small and large receptive fields--what do you think limits your ability to tell where the receptive field is? If you move bars very quickly what kinds of problems does this cause?</li> 
</ul>
	<canvas id="canvas3" width=1000 height=700></canvas>
	<!-- this back canvas will be used to render the RF and stimulus at low resolution to calculate overlap -->
	<br>
	<br>
	<!--   -->
	<p>When you're finished exploring the questions at the top of the page, continue with the MATLAB tutorial.</p>
</div>


<div id="block4">
	<h2>Part 2: Retinotopic maps in visual cortex</h2>
	<p>In visual cortex voxels that respond to neighboring regions of the visual field tend to cluster together. These form <b>retinotopic maps</b> that can be uncovered using the stimuli you just learned about. In the next demonstration we're going to show you examples of the retinotopic maps and how they respond to wedge, ring, and bar stimuli. This section is designed to help you gain an intuition about how these stimuli evoke responses across all of visual cortex.</p>
	<p>On the next screen we're going to show you a <b>flat map</b>, which is a small piece of cortex flattened to make it easier to see the retinotopic areas. These would normally be folded into the surface of the brain. To generate a flat map we take the occipital cortex (the back of this brain), as shown on this image, and cut out just the back chunk.</p>
	<img src="images/surface1.png"/>
	<p>Which gives us something like this:</p>
	<img src="images/surface2.png" width=300/>
	<p>We then "flatten" this out, coloring the sulci darker and gyri lighter to make it clear what the original topography was.</p>
	<img src="images/flat_roi.png"/>
	<p>Notice that there are ROIs on this image--to orient you we can show you the original surface these were generated from. This version of it is "inflated", which again is a useful tool to see the topography of the retinotopic maps. Notice how the center of the map is right at the tip of the occipital cortex? In humans this is where we find voxels that have receptive fields in the fovea. Before you go on consider this question: in our data we don't usually map the fovea, why do you think that is?</p>
	<img src="images/surface.png" width=500/>
	<p>In the next MATLAB sections you'll be working with these flat maps to understand how the wedge/ring/bar stimuli are useful for finding regions of cortex that respond with similar properties. You'll see a display like the one below and like before you'll be able to control the stimulus. This time, we'll show you the <b>predicted cortical response</b> based on the population receptive field encoding model. Yellow colors indicate strong responses, while a lack of color means that voxel is completely inactive.</p>
	<img src="images/example2.png"/>
</div>

<div id="block5">
	<h2>Part 2: Retinotopic maps in visual cortex</h2>
	<ul>
		<li>First, try using the ring stimulus. We've centered this flat map on the <b>fovea</b>, so you should see expanding responses leaving from that point and moving outwards. The first set of retinotopic maps in visual cortex (V1->V4) all spread out from this first fovea. Later retinotopic maps like MT, the ventral occipital maps, and the intraparietal maps have their own complete hemifields (fovea and periphery).</li>
		<li>Next try using the wedge stimulus. Notice how near vertical and horizontal you can identify the <b>boundaries</b> between retinotopic maps, at these points the maps "flip" and reverse direction. If that's confusing try drawing a picture on the whiteboard. With the wedge stimulus you should be able to clearly identify V1 to V3, and the instructors/TAs can help you identify some of the other maps on this flat map.</li>
		<li>Finally try the bar stimulus: notice that the bar stimulus doesn't make either the boundaries between regions or the fovea/periphery immediately obvious. The bar stimulus requires an encoding model to be useful--on its own it can't be used to map retinotopic cortex. In the next section of the tutorial you'll be focusing on building an encoding model that generates the kinds of maps we use to draw retinotopic maps.</li>
	</ul>
	<canvas id="canvas5" width=1000 height=700></canvas>
	<br>	<br>

	<!--   -->
	<p>When you're finished exploring the questions at the top of the page, continue with the MATLAB tutorial.</p>
</div>

<div id="block6">
	<h2>Part 3: Encoding and decoding</h2>
	<p>The population receptive field model is an encoding model--it specifies how a stimulus will be encoded as a representation in the brain. One popular use of encoding models is their power to <b>decode</b>, from just the measures of brain representations, what stimulus might have been shown in the world. Decoding has become a powerful tool for cognitive neuroscience and is now being used as part of the standard set of paradigms to test and understand cognition.</p>
	<p>One use of decoding in vision is to get an estimate of how the brain is representing the visual world. When cognitive changes occur, for example when we focus our attention on a spatial location, we might expect that the brain's representation of the world will change even though the stimulus input remains the same. Other experiments pit two alternative stimuli against each other and then use our ability to "read out" which stimulus was shown as a measure of the brain representation's fidelity.</p>
	<p>In the next slide you'll be shown a screen like the one below. The circle on the left represents the visual field, the flat map on the right is the flattended cortical surface of the left visual cortex. You'll see activity appear in response to the stimulus, according to whether each voxel is activated y a particular stimulus. You can click and drag to draw a stimulus, shift+click will clear the screen. Remember that this is the <b>left visual cortex</b> so stimuli in only some parts of the visual field will have an effect.</p>
	<img src="images/example3.png"/>
</div>

<div id="block7">
	<h2>Part 3: Encoding and decoding</h2>
	<p>To test out how the pRF encoding model can be used to predict the respones for different stimuli try out the following. Remember you can click+drag to draw, and shift+click to clear.</p>
	<ul>
		<li>With your neighbor, each draw an X in the right hemifield, take a screenshot of the responses, then draw an O, and take a screenshot (command+shift+4 on a mac). Hide the demo page and open just the screenshots, then take a look at your neighbor's screenshots, can you tell which is the O and which is the X? Despite the noise you each added by drawing slightly different shapes, it should be pretty clear. This is how we use an encoding model to perform <b>decoding</b>: we make predictions about what we expect and compare them to reality. The predicted response that best matches reality informs us about which stimulus was most likely to have been shown.</li>
	</ul>
	<canvas id="canvas7" width=1000 height=700></canvas>
	<br>	<br>

	<p>When you're finished exploring the questions at the top of the page, continue with the MATLAB tutorial (this is the end of the demo).</p>
</div>

<div id="endblock">
	<h2>Tutorial complete!</h2>
	<p>As a reminder the learning goals for this tutorial were to have a better understanding of:</p>
	<ul>
		<li>How the receptive field of neurons in visual cortex is identified using high contrast visual stimuli.</li>
		<li>How visual cortex shows a topography of receptive fields and how we can use that to identify cortical regions.</li>
		<li>How we can use the population receptive field encoding model to study the spatial distribution of information in cortex.</li>
	</ul>
</div>


							</section>
							<section id="continue">
								<a class="button special" onclick="prev();">Go back</a>
								<a class="button special" onclick="next();">Continue</a>
							</section>
						<!-- End Content -->
					</div>
				</div>

			<!-- Footer -->
				<footer id="footer">
					<ul class="copyright">
						<li>&copy; Dan Birman 2015-Present</li><li><a href="https://github.com/dbirman/web/" target="_blank">Code<a/></li>
					</ul>
				</footer>

		</div>

		<!-- Local CSS -->
			<!-- <link rel="stylesheet" href="psych50.css" /> -->
		<!-- Scripts -->
			<script src="../assets/js/shared_code.js"></script>
			<script src="prf.js"></script>

			<script>launch();</script>
	</body>
</html>


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-34324563-2', 'auto');
  ga('send', 'pageview');

</script>
